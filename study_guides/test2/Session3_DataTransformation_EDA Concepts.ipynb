{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40393eff-b94e-4f48-808a-dbfc16178213",
   "metadata": {},
   "source": [
    "# Session 3 - Data Transformations, DateTime Operations & EDA Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eebd02-8b3a-4fa8-94b9-b701ae03d7d4",
   "metadata": {},
   "source": [
    "**Q1** - DateTime Feature Engineering\n",
    "\n",
    "You have a DataFrame with a timestamp column (string format: \"2024-03-15 14:30:00\"). You need to create three new features: hour_of_day, day_name, and is_weekend. What's the correct sequence of operations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482e4e4-ad1f-4e55-83ed-2ed39e5d93e0",
   "metadata": {},
   "source": [
    "```python\n",
    "df.['date'] = pd.to_datetime(df['date']) \n",
    "\n",
    "df.['day_name'] = df['date'].dt.day_name\n",
    "df.['is_weekend'] = df['date'].dt.dayofweek.isin([5,6])\n",
    "df.['hour_of_day'] = df['date'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65ccd9-f92a-4cbc-9adb-b9c5079674f2",
   "metadata": {},
   "source": [
    "**Q2** - Vectorized vs .apply() Decision\n",
    "\n",
    "You need to create a new column that categorizes trip durations:\n",
    "\n",
    "* \"short\" if < 30 minutes\n",
    "* \"medium\" if 30-60 minutes\n",
    "* \"long\" if > 60 minutes\n",
    "\n",
    "Should you use vectorized operations or .apply() for this task? Briefly explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3669f5-468b-46b4-929d-b2bff0911cc3",
   "metadata": {},
   "source": [
    "Use .apply() for this task because of its a complex ask to split the filter up and return a string back, essentially creating a categorical column based on filter results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287607e-1f32-44d4-b77c-2328dbec6216",
   "metadata": {},
   "source": [
    "**INCORRECT** --- Simple logic for a vectorized approach using np.select() or condition chaining.  \n",
    "\n",
    "_preferred approach_\n",
    "\n",
    "```python\n",
    "conditions = [\n",
    "    df['duration'] < 30,\n",
    "    (df['duration'] >= 30) & (df['duration'] <= 60),\n",
    "    df['duration'] > 60\n",
    "]\n",
    "\n",
    "choices = ['short','medium','long']\n",
    "\n",
    "df['category'] = np.select(conditions,choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d92dd9a-e814-4cb6-84e5-9f3c5a8c7f8f",
   "metadata": {},
   "source": [
    "**Q3**  - Anscombe's Quartet - The Core Lesson \n",
    "\n",
    "Four datasets have nearly identical summary statistics (mean, std dev, correlation). What is the fundamental lesson Anscombe's Quartet teaches us about data analysis, and why does this matter for real-world work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2c5c1-484b-4f1a-b3e7-a95d3186058f",
   "metadata": {},
   "source": [
    "The core lesson is that even though the datasets are statistically similar, their visualizations are different which tells us that the data sets' real world significances are not at all similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef7bd61-1589-4d7f-a3b2-28b59c2ff121",
   "metadata": {},
   "source": [
    "**Fundamental Lesson** : \n",
    "Summary statistics alone (mean, std dev, correlation) can be misleading or insufficient. Datasets with identical statistics can have completely different structures, patterns, and meanings. You MUST visualize your data to understand what's actually going on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd43dd5a-ef57-4d4c-b661-28beb4b750b1",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "Q1 - \n",
    "```python\n",
    "df['date'] = pd.to_datetime(df['date']) \n",
    "\n",
    "df['day_name'] = df['date'].dt.day_name\n",
    "df['is_weekend'] = df['date'].dt.dayofweek.isin([5,6])\n",
    "df['hour_of_day'] = df['date'].dt.hour\n",
    "```\n",
    "\n",
    "Q2 - \n",
    "Use .apply() for this task because of its a complex ask to split the filter up and return a string back, essentially creating a categorical column based on filter results. \n",
    "\n",
    "Q3 - \n",
    "The core lesson is that even though the datasets are statistically similar, their visualizations are different which tells us that the data sets' real world significances are not at all similar. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d0e17-c242-411e-b1e1-e1ae54980767",
   "metadata": {},
   "source": [
    "**Q4** - Data Type Identification\n",
    "\n",
    "Classify each variable and explain what analysis is appropriate:\n",
    "\n",
    "1) Customer satisfaction rating (1-5 stars)\n",
    "2) Temperature in Celsius\n",
    "3) Customer ID number\n",
    "4) Payment method (credit, debit, cash, crypto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29558262-26b3-4170-8901-14530731a80f",
   "metadata": {},
   "source": [
    "1 - ordered categorical (it will appear as a number but there are only 5 options and they need to be considered in terms of their order)\n",
    "2 - continuous (float64 the value could be any number with a decimal included)\n",
    "3 - object (customer ID, could technically be an integer but we wouldn't want to accidentally aggregate these numbers)\n",
    "4 - unordered categorical (fixed number of values in a list, string type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c7859d-ef55-4759-9ad5-77d98a137e54",
   "metadata": {},
   "source": [
    "**Q5** - Validation vs Verification\n",
    "\n",
    "You're analyzing taxi trip data. You calculate that the average trip duration is 15.3 minutes and your code runs without errors. Have you performed validation, verification, both, or neither? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ec896-57dc-4283-a2af-e70d02bd11e0",
   "metadata": {},
   "source": [
    "Verification - The code works\n",
    "Validation - The results are good\n",
    "\n",
    "for this example the code is verified but not validated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426c8d4-98af-4fdc-ac4d-6b0229f4fb03",
   "metadata": {},
   "source": [
    "**Q6** - Feature Engineering Performance\n",
    "\n",
    "You have a 1 million row DataFrame. You need to create a feature that extracts the hour from a datetime column. Estimate the performance difference between using .dt.hour vs .apply(lambda x: x.hour). Which would you choose and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bffdb0a-c4e1-4755-b36d-148c78fa4c52",
   "metadata": {},
   "source": [
    "I would use dt.hour over .apply(lambda) because .dt is vectorized and optimized for this operation and the apply will have to execute row-by-row making the process much longer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb8e72f-6751-406e-a279-2e92b45ac3be",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "Q4 - \n",
    "\n",
    "1 - ordered categorical (it will appear as a number but there are only 5 options and they need to be considered in terms of their order)\n",
    "2 - continuous (float64 the value could be any number with a decimal included)\n",
    "3 - object (customer ID, could technically be an integer but we wouldn't want to accidentally aggregate these numbers)\n",
    "4 - unordered categorical (fixed number of values in a list, string type)\n",
    "\n",
    "Q5 - \n",
    "Verification - The code works\n",
    "Validation - The results are good\n",
    "\n",
    "for this example the code is verified but not validated. \n",
    "\n",
    "Q6 - \n",
    "I would use dt.hour over .apply(lambda) because .dt is vectorized and optimized for this operation and the apply will have to execute row-by-row making the process much longer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71d3c9-29f3-47e3-8509-bb29823545a6",
   "metadata": {},
   "source": [
    "**Q7** - Descriptive Statistics - Why Multiple Measures?\n",
    "\n",
    "You calculate the mean trip duration is 15 minutes. Your colleague says \"Great, now we understand trip durations!\" Why is relying on the mean alone potentially misleading? Name at least two other statistics you'd want to check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa2e20-e369-4d30-b09b-9537b83cc679",
   "metadata": {},
   "source": [
    "Relying on the mean hides outliers. We'd want to check the min, max, standard deviation, and the inner quartile ranges. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7991fc-2da6-4ab6-b75b-f05cc8dc74c9",
   "metadata": {},
   "source": [
    "**Q8** - DataFrame Terminology\n",
    "\n",
    "In a machine learning context with a DataFrame predicting taxi fares:\n",
    "\n",
    "What do we call the columns trip_distance, passenger_count, hour_of_day?\n",
    "What do we call the column fare_amount (what we're predicting)?\n",
    "What do we call each row?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf1f4f7-9ca9-4e66-9006-0d681d15021f",
   "metadata": {},
   "source": [
    "The columns are features, the the fare_amount is the target , and the rows are observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ec2be5-cebe-4552-8174-495d6ab1c799",
   "metadata": {},
   "source": [
    "**Q9** -  EDA Philosophy - Classical vs Exploratory\n",
    "\n",
    "Classical statistics emphasizes hypothesis testing and p-values before looking at data. Exploratory Data Analysis (EDA) emphasizes visualization and pattern discovery first. In the taxi trip dataset, which approach would you use to decide if you should create separate models for weekday vs weekend trips? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69c2802-f7c7-4372-b49a-2ed49ec826b1",
   "metadata": {},
   "source": [
    "I would chose the EDA approach, because I can easily split and compare the differences in the data visualy to determine if it would be valuable to assess them seperately. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a319edc-52ed-483b-a65c-d58d473257df",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "Q7 - \n",
    "Relying on the mean hides outliers. We'd want to check the min, max, standard deviation, and the inner quartile ranges. \n",
    "\n",
    "Q8 - \n",
    "The columns are features, the the fare_amount is the target , and the rows are observations.\n",
    "\n",
    "Q9 - \n",
    "I would chose the EDA approach, because I can easily split and compare the differences in the data visualy to determine if it would be valuable to assess them seperately. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c000ca-3d64-4843-8aa9-83059f5b34fc",
   "metadata": {},
   "source": [
    "**Q10** -  Real-World Scenario - DateTime Feature Engineering\n",
    "\n",
    "You're analyzing ride-share data and notice the model performs poorly for early morning trips (12am-5am). You have a pickup_datetime column. What temporal features would you engineer to help the model distinguish these trips, and why might they be predictive?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b910eab-6cd3-472a-b2c0-e7997bda10cf",
   "metadata": {},
   "source": [
    "I would engineer a categorical field for df['time_of_day'] for example which filters for hourly ['early_morning','morning','afternoon','early evening','night']. This may help the model to perform but condensing these trips into a category so that the sample size is larger. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94c6f4-04e3-4af9-8b7e-d93f3cbacddb",
   "metadata": {},
   "source": [
    "**Q11** - Anscombe's Quartet Application\n",
    "\n",
    "Your colleague reports: \"I analyzed our customer satisfaction data. Mean = 3.2 stars, correlation between price and satisfaction = -0.15. Conclusion: price barely affects satisfaction.\" Based on Anscombe's Quartet lesson, what would you ask them before accepting this conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff64f4ae-b0e0-4267-9924-d67d99825b0c",
   "metadata": {},
   "source": [
    "Based on Anscombe's Quartet lesson, which emphasizes visualation over statistical representation... I would ask what visualizations they put together and what they were able to interpret from them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6f8edd-63b1-423d-a3ac-634016fe2d83",
   "metadata": {},
   "source": [
    "**Q12** - Data Type and Analysis Choice\n",
    "\n",
    "You're building a model to predict taxi fares. You have a pickup_borough feature (Manhattan, Brooklyn, Queens, Bronx, Staten Island). Your colleague suggests encoding it as numbers 1-5 and using it directly in linear regression. What's wrong with this approach? What data type is pickup_borough and how should it be handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345e9ad9-5047-4e26-82db-fc140d08ea8a",
   "metadata": {},
   "source": [
    "pickup_borough feature is a categorical feature already and doesn't need to be recoded. It should be modeled as mode. Recoding as a numbers will impact the regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2af3a6-f4c1-436a-98c0-1b45b1a58f59",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "Q10 - I would engineer a categorical field for df['time_of_day'] for example which filters for hourly ['early_morning','morning','afternoon','early evening','night']. This may help the model to perform but condensing these trips into a category so that the sample size is larger. \n",
    "\n",
    "Q11 - Based on Anscombe's Quartet lesson, which emphasizes visualation over statistical representation... I would ask what visualizations they put together and what they were able to interpret from them. \n",
    "\n",
    "Q12 - \n",
    "pickup_borough feature is a categorical feature already and doesn't need to be recoded. It should be modeled as mode. Recoding as a numbers will impact the regression model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
