{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "984da6c9-b1f0-481e-87bb-c99adf51452a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Session 2 - Pandas Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b453507e-f872-4546-8bf7-878151fbb6c4",
   "metadata": {},
   "source": [
    "**Q1** You need to select the 5th through 10th rows (inclusive) from a DataFrame df using position-based indexing. Which is correct?\n",
    "\n",
    "``````\n",
    "a) df.loc[4:9]\n",
    "b) df.iloc[4:9]\n",
    "c) df.iloc[5:10]\n",
    "d) df.loc[5:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52edb7-7f84-4fcd-9ed9-05aea3a5752d",
   "metadata": {},
   "source": [
    "C - iloc is inclusive so df.iloc[5:10] includes *rows* 5 through 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4b21a6-7e8a-4c48-be3a-a0123107d86b",
   "metadata": {},
   "source": [
    "INCORRECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebce86-6b10-4590-bbcf-000cc40aaf8d",
   "metadata": {},
   "source": [
    "**Q2** Given this DataFrame:\n",
    "\n",
    "```\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
    "```\n",
    "\n",
    "What does df['B'] return, and what does df[['B', 'C']] return? (Series vs DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952922e6-3794-46b9-9473-c91dddd1fb7c",
   "metadata": {},
   "source": [
    "df['B'] returns a Series, which is a one dimensional list type of object while df[['B','C']] returns a 2D DataFrame. Like a normal table with rows and columns and an index. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664e1af-06bd-4bbf-9d44-058ce3f06866",
   "metadata": {},
   "source": [
    "**Q3** You want to filter a DataFrame for rows where city is one of ['NYC', 'LA', 'Chicago', 'Boston', 'Seattle']. Write this using .isin() instead of multiple | conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3192ff23-197a-4e41-932d-33fad1a7b610",
   "metadata": {},
   "source": [
    "```\n",
    "city_list =  ['NYC', 'LA', 'Chicago', 'Boston', 'Seattle']\n",
    "df['city'].isin(city_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e977d-484a-42b6-895d-790ccceacd46",
   "metadata": {},
   "source": [
    "PARTIALLY INCORRECT ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b66cc1-522f-4299-b990-4dac1807f2d0",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "Q1- C - iloc is inclusive so df.iloc[5:10] includes rows 5 through 10\n",
    "\n",
    "Q2- df['B'] returns a Series, which is a one dimensional list type of object while df[['B','C']] returns a 2D DataFrame. Like a normal table with rows and columns and an index.\n",
    "\n",
    "Q3- \n",
    "```\n",
    "city_list = ['NYC', 'LA', 'Chicago', 'Boston', 'Seattle'] \n",
    "df['city'].isin(city_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11353ee-0f84-4d97-8684-64bd55662f8a",
   "metadata": {},
   "source": [
    "**Q4** What's the difference between these two operations?\n",
    "\n",
    "```\n",
    "result1 = df.loc[df['price'] > 100, 'product']\n",
    "result2 = df.loc[df['price'] > 100, ['product']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7c5e8-c875-4113-af9b-49aa8e116299",
   "metadata": {},
   "source": [
    "I'm not really sure but I see the bracket syntax is different. My guess is result1 uses .loc to look for prices over 100 with a product T or F. result2 uses .loc to look for prices over 100 and lines them up with the product values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec5aba-95f3-45db-9865-65aba882ad9a",
   "metadata": {},
   "source": [
    "**PARTIAL** result1 returns a series and result2 returns a DataFrame... Like Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb28066-d50d-4dde-9f47-a0efcde0de4d",
   "metadata": {},
   "source": [
    "**Q5** You load a CSV with pd.read_csv('sales.csv'). What method would you use to quickly check: \n",
    "1) column data types\n",
    "2) how many non-null values each column has, \n",
    "3) memory usage?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3e79ab-d4e9-48bc-8a4a-0bafc19858d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "df.info() has each columns type, number of non-values and memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1667055c-b99e-444b-97bd-ab202371c32a",
   "metadata": {},
   "source": [
    "**Q6** Why do you need parentheses around each condition when combining boolean filters?\n",
    "```\n",
    "# Why this?\n",
    "df[(df['age'] > 25) & (df['salary'] > 50000)]\n",
    "\n",
    "# Instead of this?\n",
    "df[df['age'] > 25 & df['salary'] > 50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a4adb4-ea67-4273-bd5a-66cf44b25ee6",
   "metadata": {},
   "source": [
    "Parenthesis are needed to seperate the individual boolean conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c570b-944e-4069-972a-dfb8a142f3f4",
   "metadata": {},
   "source": [
    "**PARTIAL** Parenthesis are needed because of operator precedence. Without them the `&` evalueats before the comparisons. Also critical is `and` cannot be used here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54157c88-6978-48a7-adfd-f449e67977bb",
   "metadata": {},
   "source": [
    "**ANSWERS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ffe37e-0e0b-4045-9adf-3b4555e91085",
   "metadata": {},
   "source": [
    "Q4 - I'm not really sure but I see the bracket syntax is different. My guess is result1 uses .loc to look for prices over 100 with a product T or F. result2 uses .loc to look for prices over 100 and lines them up with the product values. \n",
    "\n",
    "Q5 - df.info() has each columns type, number of non-values and memory usage\n",
    "\n",
    "Q6 - Parenthesis are needed to seperate the individual boolean conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f229525-973b-4819-97a2-bd9ce9f2929e",
   "metadata": {},
   "source": [
    "**Q7** Whats the difference between these NaN-chcecking approaches? \n",
    "```python\n",
    "approach1 = df['column'].isna().sum()\n",
    "approach2 = df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dead356-619d-4491-af2f-5f1c9214c1fc",
   "metadata": {},
   "source": [
    "approach1 checks specificaly in the 'column' returning just an integer, while approach2 checks over the whole dataframe returning a count of isna() for each column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f210f0-a513-444a-a69c-e579ef3231e1",
   "metadata": {},
   "source": [
    "**Q8** You have a datetime column 'date'. Write the pd.read_csv() call to:\n",
    "\n",
    "* Parse the date column as datetime\n",
    "* Set date as the index\n",
    "* Treat the string 'N/A' as missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c1359-87d9-4dc1-ae0f-b2e8def10089",
   "metadata": {},
   "source": [
    "pd.read_csv('data', parse_date='date', index_col ='date', na_values = ['N/A']) .... I had to look this up in the lecture file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c3e564-53ae-483d-a33b-a744923a9f0e",
   "metadata": {},
   "source": [
    "**Q9** Given \n",
    "```python\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "```\n",
    "what does this return?\n",
    "```python\n",
    "df.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70448cf7-25c5-4818-970c-9ef544bf6d61",
   "metadata": {},
   "source": [
    "This returns all rows column 1. Also had to look this one up because I was thinking iloc is for rows only but the , means rows and column(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b351ac-8e45-4366-9351-9070c63180f1",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "Q7 - approach1 checks specificaly in the 'column' returning just an integer, while approach2 checks over the whole dataframe returning a count of isna() for each column.\n",
    "\n",
    "Q8 - pd.read_csv('data', parse_date='date', index_col ='date', na_values = ['N/A']) .... I had to look this up in the lecture file. \n",
    "\n",
    "Q9 - This returns all rows column 1. Also had to look this one up because I was thinking iloc is for rows only but the , means rows and column(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d13b31-b1b5-4658-9730-68bf086d0190",
   "metadata": {},
   "source": [
    "**Q10** What does this method chaining pattern accomplish?\n",
    "\n",
    "```python\n",
    "df_clean = (df[df['price'] > 0]\n",
    "            .dropna()\n",
    "            .reset_index(drop=True))\n",
    "```\n",
    "Why does it work? What would happen if Pandas methods modified in-place by default?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db3498-ee15-48b5-9b73-b0b0f607c59d",
   "metadata": {},
   "source": [
    "I'm not too sure on the specifics. But it cleans the data frame of observations with either NaN or not greater than 0. So in order... it first filters the DataFrame looking for prices greater than 0. From that result, it drops rows where the value is NaN to the bottom. Then resests the index. Drop = True means that the values are dropped from the table. ... actually it means that the original index is dropped ... I looked it up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44239e4f-d0db-4d35-8ed6-b1bd71dc0285",
   "metadata": {},
   "source": [
    "**Q11**  You have a DataFrame with datetime index. How would you select all rows from October 15-17, 2024 using .loc[]?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a327d-d330-4333-aba6-acd3044035af",
   "metadata": {},
   "source": [
    "df.loc[2024-10-15:2024-10-17]  ... I also looked this up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5063034-93c1-4ee6-be37-17c4df8dd917",
   "metadata": {},
   "source": [
    "**Q12**What's the practical advantage of .query() over boolean indexing when you have complex conditions with multiple variables?\n",
    "\n",
    "```python\n",
    "# Boolean indexing\n",
    "min_price = 50\n",
    "max_qty = 100\n",
    "result = df[(df['price'] >= min_price) & (df['quantity'] <= max_qty)]\n",
    "\n",
    "# vs .query()\n",
    "result = df.query('price >= @min_price and quantity <= @max_qty')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051fb448-417a-4aae-88a6-e71ee3b5fc2f",
   "metadata": {},
   "source": [
    "using the .query() is more human readable than the boolean indexing which makes it easier to write and interpret (human-side) and maintain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c3cc6-0731-4082-a2d3-6c344e6e9e19",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "Q10 - I'm not too sure on the specifics. But it cleans the data frame of observations with either NaN or not greater than 0. So in order... it first filters the DataFrame looking for prices greater than 0. From that result, it drops rows where the value is NaN to the bottom. Then resests the index. Drop = True means that the values are dropped from the table. ... actually it means that the original index is dropped ... I looked it up\n",
    "\n",
    "Q11 - df.loc[2024-10-15:2024-10-17]  ... I also looked this up\n",
    "\n",
    "Q12 - using the .query() is more human readable than the boolean indexing which makes it easier to write and interpret (human-side) and maintain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec0281-cdf4-471d-aef4-9057230183a0",
   "metadata": {},
   "source": [
    "**Q13** What's wrong with this code, and how would you fix it?\n",
    "\n",
    "```python\n",
    "high_sales = df[df['sales'] > 1000 & df['region'] == 'West']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25252dd8-0b84-4fd8-996c-bcffa4f71903",
   "metadata": {},
   "source": [
    "There are no parenthesis in the boolean conditioning. high_sales = df[(df['sales'] > 1000) & (df['region'] == 'West')]. Does this return a series because there are not [[]]? or is it returning the whole df because its boolean condition? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e268d76-29b6-4545-ac09-cd38c4ec377a",
   "metadata": {},
   "source": [
    "**Q14** You load a CSV and see this with `.info()`:\n",
    "\n",
    "```python\n",
    "date     1000 non-null object\n",
    "amount   1000 non-null object\n",
    "```\n",
    "What's the problem? How would you fix it during the pd.read_csv() call?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7aa34-9ff1-40b0-8191-237772cc9d54",
   "metadata": {},
   "source": [
    "I would parse the dates and load the amount data in with explicit dtypes in a dictionary as in: \n",
    "\n",
    "```python\n",
    "pd.read_csv('data', \n",
    "            parse_dates = ['date'], \n",
    "            dtype = {'amount':'int64'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af62aef-8458-452f-ae5c-4abca2cec127",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Q15** Given this DataFrame with custom index:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({'value': [10, 20, 30]}, index=['A', 'B', 'C'])\n",
    "```\n",
    "What's the difference between:\n",
    "\n",
    "* df.loc['A':'B']\n",
    "* df.iloc[0:2]\n",
    "\n",
    "Which rows does each return?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d448df1-ffdc-40b7-aa98-3879ac207c62",
   "metadata": {},
   "source": [
    "df.loc['A':'B'] brings in a dataFrame with columns A through B.\n",
    "df.iloc[0:2] brings in a dataframe with rows 0 & 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9edfbe5-6892-4e0b-9c9d-8a781457371b",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "Q13 - There are no parenthesis in the boolean conditioning. high_sales = df[(df['sales'] > 1000) & (df['region'] == 'West')]. Does this return a series because there are not [[]]? or is it returning the whole df because its boolean condition? \n",
    "\n",
    "Q14 - I would parse the dates and load the amount data in with explicit dtypes in a dictionary as in: \n",
    "\n",
    "```python\n",
    "pd.read_csv('data', \n",
    "            parse_dates = ['date'], \n",
    "            dtype = {'amount':'int64'})\n",
    "```\n",
    "\n",
    "Q15 -\n",
    "\n",
    "* df.loc['A':'B'] brings in a dataFrame with columns A through B.\n",
    "* df.iloc[0:2] brings in a dataframe with rows 0 & 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba1a09-1dbf-4053-9b4d-26a15f29e6cb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
