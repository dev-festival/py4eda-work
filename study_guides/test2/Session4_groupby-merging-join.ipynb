{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0cb22c-1eeb-4869-ac37-156bcc38d41b",
   "metadata": {},
   "source": [
    "# Session 4 - Advanced Pandas, Groupby & Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07385ae1-4206-4ca4-b313-16a166b66af1",
   "metadata": {},
   "source": [
    "**Q1** In your own words, explain the split-apply-combine pattern. What happens in each phase when you run df.groupby('category')['sales'].mean()?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1986e96e-d665-49f2-bd59-8a8b5d336839",
   "metadata": {},
   "source": [
    "*Q1* - When using groupby, first pandas will **split** the data into groups. It **applies** the mean individually to the groups then it **combines** the groups data back into one data frame. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81959b32-bf9a-410c-a589-b7b471ff903c",
   "metadata": {},
   "source": [
    "**Q2**  You run this code:\n",
    "\n",
    "```python\n",
    "df.groupby('store')['revenue'].count()\n",
    "df.groupby('store')['revenue'].size()\n",
    "```\n",
    "\n",
    "Both groupby operations use the same column. What's the key difference in what these two methods count? When would each be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee6f0f-8679-4113-99e1-b1079d5c5d40",
   "metadata": {},
   "source": [
    "*Q2* - *I had to look this up* I did assume that size was the total rows but I was not sure how count would be different. .cout() counts the non-null values in the specified coulmns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc5669-6e6d-4c79-b358-2eda9511b7d9",
   "metadata": {},
   "source": [
    "**Q3** Predict the output structure. Given:\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'region': ['East', 'East', 'West', 'West'],\n",
    "    'sales': [100, 200, 150, 250]\n",
    "})\n",
    "result = df.groupby('region')['sales'].sum()\n",
    "```\n",
    "Will result be a Series or DataFrame? What will the index be? How many rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d2a15a-a71d-4805-ba10-ba4df01498ae",
   "metadata": {},
   "source": [
    "*Q3* - The result will be a Series with the region as the index and 2 rows. The sum of the sales by East and West as the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50178719-9146-4911-89ee-3a02dea74df6",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "*Q1* - When using groupby, first pandas will **split** the data into groups. It **applies** the mean individually to the groups then it **combines** the groups data back into one data frame. \n",
    "\n",
    "*Q2* - *I had to look this up* I did assume that size was the total rows but I was not sure how count would be different. .cout() counts the non-null values in the specified coulmns.\n",
    "\n",
    "*Q3* - The result will be a Series with the region as the index and 2 rows. The sum of the sales by East and West as the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1b5115-4298-4bd1-b6c5-9f427c49fe4e",
   "metadata": {},
   "source": [
    "**Q4** You need to add a column showing each employee's salary as a percentage of their department's total salary. Which method do you use and why?\n",
    "\n",
    "* .agg()\n",
    "* .transform()\n",
    "* .apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1233d9c-db22-4b79-94b1-4d72fc1433f6",
   "metadata": {},
   "source": [
    "*Q4* - I believe this is .transform(), it doesn't seem to need complex logic like .apply() and .agg() would reduce the data to group summaries. Although I'm not sure how to apply this calculation with the individual value and the group value.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35f1033-fde6-43c2-b535-8ee1dc4c6373",
   "metadata": {},
   "source": [
    "**Q5** Scenario: You want to create a summary table showing, for each product category, the mean price, max price, and total quantity sold. Which method lets you compute multiple different aggregations in one operation? What does the resulting structure look like (Series or DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01992026-174f-4000-a035-19e370294802",
   "metadata": {},
   "source": [
    "*Q5* - This would be a groupby with named aggregations. Because there are multiple columnar aggs than the result must be a DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8154fae-0888-4203-adc5-da3ac10715ea",
   "metadata": {},
   "source": [
    "**Q6** You run:\n",
    "\n",
    "```python\n",
    "df.groupby('team')['score'].transform('mean')\n",
    "```\n",
    "The original DataFrame has 12 rows. How many values will transform() return? What will those values represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2937d9c9-daa1-4cd0-ab75-cfc614f9303b",
   "metadata": {},
   "source": [
    "*Q6* - Transform keeps the dimensions the same, the values will be the mean for the row's team represented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ce6d5-acfe-4553-b599-7955fe1e1bf2",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "*Q4* - I believe this is .transform(), it doesn't seem to need complex logic like .apply() and .agg() would reduce the data to group summaries. Although I'm not sure how to apply this calculation with the individual value and the group value.  \n",
    "\n",
    "*Q5* - This would be a groupby with named aggregations. Because there are multiple columnar aggs than the result must be a DataFrame. \n",
    "\n",
    "*Q6* - Transform keeps the dimensions the same, the values will be the mean for the row's team represented\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397ef6e8-eff2-4472-be15-9f3d1cb70312",
   "metadata": {},
   "source": [
    "**Q7** After running \n",
    "```python\n",
    "result = df.groupby('region')['sales'].sum()\n",
    "```\n",
    "you want to use 'region' as a regular column (not the index). What method do you call and why is this often necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db4ef88-a33d-4310-b83d-4caf17cd4ddb",
   "metadata": {},
   "source": [
    "*Q7* - You want to use .reset_index(), you want to do this because the groupby column becomes the index. But I'm not sure when to use drop=True or why. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038256a-3ae0-4438-a4e9-9e9f86a57f4b",
   "metadata": {},
   "source": [
    "**Q8** You want to keep only groups where the average sales exceed $500. Which groupby method lets you filter entire groups based on a condition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0318dd5-1196-4684-b215-898a9f65bfcc",
   "metadata": {},
   "source": [
    "*Q8* - I had to look this one up too, but a groupby with filtering method using a lambda function will let you achieve this result. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f1fae5-9f68-46ee-bfcb-4e425e019fa7",
   "metadata": {},
   "source": [
    "**Q9** Predict the output:\n",
    "```Python\n",
    "df = pd.DataFrame({\n",
    "    'dept': ['Sales', 'Sales', 'IT', 'IT'],\n",
    "    'team': ['A', 'B', 'A', 'A'],\n",
    "    'revenue': [100, 150, 200, 250]\n",
    "})\n",
    "result = df.groupby(['dept', 'team'])['revenue'].sum()\n",
    "```\n",
    "What type of index will result have? How many rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be15a100-6167-46c1-b755-59d8a5ce87dd",
   "metadata": {},
   "source": [
    "*Q9* - This will have a heirarchical index with 4 rows. Sales - A , B then IT - A, B. I think. It looks like IT doesn't have a B team but the heirarchical index may force it to be there. I'm not sure just on sight reading or by memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686dc2b1-8a81-4730-bad4-1f1e7289449c",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "*Q7* - You want to use .reset_index(), you want to do this because the groupby column becomes the index. But I'm not sure when to use drop=True or why. \n",
    "\n",
    "*Q8* - I had to look this one up too, but a groupby with filtering method using a lambda function will let you achieve this result. \n",
    "\n",
    "*Q9* - This will have a heirarchical index with 4 rows. Sales - A , B then IT - A, B. I think. It looks like IT doesn't have a B team but the heirarchical index may force it to be there. I'm not sure just on sight reading or by memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da37b1-9ee5-4665-b852-f22ec08d58c4",
   "metadata": {},
   "source": [
    "**Q10** Explain the difference between a primary key and a foreign key. If a customers table has a customer_id column, and an orders table also has a customer_id column, which is which?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4721878-52f6-4d4f-ac33-add0b1e59f75",
   "metadata": {},
   "source": [
    "*Q10* - A key is a column used to link two tables in a merge, the primary key is in the table where the values are unique and the foreign key is the same values in the 2nd table where there could be many duplicates. Customers table would have the primary key. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af2f809-3aaf-49f1-9157-fd727cc7aee7",
   "metadata": {},
   "source": [
    "**Q11** You have:\n",
    "\n",
    "* employees table: 50 rows (each employee has one dept_id)\n",
    "* departments table: 5 rows (each department ID is unique)\n",
    "\n",
    "What relationship type is this (1:1, 1:M, or M:N)? After an inner merge on dept_id, how many rows would you expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e1689-e352-40d2-b0ed-6a2cf2fdfe1e",
   "metadata": {},
   "source": [
    "*Q11* - This is a 1:M Department -> employees. After an inner merge I'd expect 50 rows where the employees have their department information in the table. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2b895-8f24-4d60-a20d-06f0e631ba81",
   "metadata": {},
   "source": [
    "**Q13** You merge two DataFrames:\n",
    "\n",
    "```python\n",
    "pd.merge(df1, df2, on='product_id', how='left')\n",
    "```\n",
    "\n",
    "df1 has 100 rows. df2 has 80 rows, but only 60 product_id values overlap with df1. How many rows will the result have? Will there be any NaN values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76023c9-d8e3-441a-a0ce-481c216a5223",
   "metadata": {},
   "source": [
    "*Q13* - You will still have 100 rows with 40 NaNs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b7cc32-133f-46da-b81e-d24ae71c5e90",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "*Q10* - A key is a column used to link two tables in a merge, the primary key is in the table where the values are unique and the foreign key is the same values in the 2nd table where there could be many duplicates. Customers table would have the primary key. \n",
    "\n",
    "*Q11* - This is a 1:M Department -> employees. After an inner merge I'd expect 50 rows where the employees have their department information in the table. \n",
    "\n",
    "*Q13* - You will still have 100 rows with 40 NaNs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57098332-a579-4960-a2ed-6b4baeedb12b",
   "metadata": {},
   "source": [
    "**Q13** What's the difference between these merge types? For each, describe when you'd use it:\n",
    "\n",
    "* how='inner'\n",
    "* how='left'\n",
    "* how='outer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481cdc73-9af6-45c1-a7a4-68d3d9b75b55",
   "metadata": {},
   "source": [
    "*Q13* \n",
    "* inner - only where both sides match\n",
    "* left - add the right table to matching left table, leave remainder of left table as NaN\n",
    "* outer - join neither matching filling NaN for missing values from each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c889543-fa81-403e-a8fc-bc055dc8d937",
   "metadata": {},
   "source": [
    "**Q14** You expect a merge to return 200 rows, but you get 800 rows instead. What relationship issue likely caused this? (Hint: Think about what happens when keys aren't unique on both sides.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ec49a-815a-4cd1-9a71-b1773fd1878e",
   "metadata": {},
   "source": [
    "*Q14* -  this could be caused by a many-to-many relationship where there's multiple matches per row on both sides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ad85e9-eea8-4856-a11b-c6be005f2470",
   "metadata": {},
   "source": [
    "**Q15** When would you use .join() instead of pd.merge()? When would you use pd.concat() instead of either?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe3013b-c74d-4e68-a0b9-c6a41b5881cb",
   "metadata": {},
   "source": [
    "*Q15* - I had to look this up. .Join() essentially merges on the index with left join as the default, although the how could be specified. \n",
    "pd.concat() is essentially appending tables to each other, stacking one on top of the other. This is useful for adding new data to existing data when the data structure is exactly the same.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f30070-dc0a-4e48-80c4-15f396a71fac",
   "metadata": {},
   "source": [
    "**ANSWERS**\n",
    "\n",
    "*Q13* \n",
    "* inner - only where both sides match\n",
    "* left - add the right table to matching left table, leave remainder of left table as NaN\n",
    "* outer - join neither matching filling NaN for missing values from each\n",
    "  \n",
    "*Q14* -  this could be caused by a many-to-many relationship where there's multiple matches per row on both sides\n",
    "\n",
    "*Q15* - I had to look this up. .Join() essentially merges on the index with left join as the default, although the how could be specified. \n",
    "pd.concat() is essentially appending tables to each other, stacking one on top of the other. This is useful for adding new data to existing data when the data structure is exactly the same.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
